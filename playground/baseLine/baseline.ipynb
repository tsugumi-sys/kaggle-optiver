{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import glob\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn import preprocessing, model_selection\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "path_root = '../input/optiver-realized-volatility-prediction'\n",
    "path_data = '../input/optiver-realized-volatility-prediction'\n",
    "path_submissions = '/'\n",
    "\n",
    "target_name = 'target'\n",
    "scores_folds = {}\n",
    "\n",
    "def log_return(list_stock_prices):\n",
    "    return np.log(list_stock_prices).diff() \n",
    "\n",
    "def realized_volatility(series_log_return):\n",
    "    return np.sqrt(np.sum(series_log_return**2))\n",
    "\n",
    "def rmspe(y_true, y_pred):\n",
    "    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n",
    "\n",
    "def get_stock_stat(stock_id : int, dataType = 'train'):\n",
    "    key = ['stock_id', 'time_id', 'seconds_in_bucket']\n",
    "    \n",
    "    #Book features\n",
    "    df_book = pd.read_parquet(os.path.join(path_data, 'book_{}.parquet/stock_id={}/'.format(dataType, stock_id)))\n",
    "    df_book['stock_id'] = stock_id\n",
    "    cols = key + [col for col in df_book.columns if col not in key]\n",
    "    df_book = df_book[cols]\n",
    "    \n",
    "    df_book['wap1'] = (df_book['bid_price1'] * df_book['ask_size1'] +\n",
    "                                    df_book['ask_price1'] * df_book['bid_size1']) / (df_book['bid_size1'] + df_book['ask_size1'])\n",
    "    df_book['wap2'] = (df_book['bid_price2'] * df_book['ask_size2'] +\n",
    "                                    df_book['ask_price2'] * df_book['bid_size2']) / (df_book['bid_size2'] + df_book['ask_size2'])\n",
    "    df_book['log_return1'] = df_book.groupby(by = ['time_id'])['wap1'].apply(log_return).fillna(0)\n",
    "    df_book['log_return2'] = df_book.groupby(by = ['time_id'])['wap2'].apply(log_return).fillna(0)\n",
    "    \n",
    "    features_to_apply_realized_volatility = ['log_return'+str(i+1) for i in range(2)]\n",
    "    stock_stat = df_book.groupby(by = ['stock_id', 'time_id'])[features_to_apply_realized_volatility]\\\n",
    "                        .agg(realized_volatility).reset_index()\n",
    "\n",
    "    #Trade features\n",
    "    trade_stat =  pd.read_parquet(os.path.join(path_data,'trade_{}.parquet/stock_id={}'.format(dataType, stock_id)))\n",
    "    trade_stat = trade_stat.sort_values(by=['time_id', 'seconds_in_bucket']).reset_index(drop=True)\n",
    "    trade_stat['stock_id'] = stock_id\n",
    "    cols = key + [col for col in trade_stat.columns if col not in key]\n",
    "    trade_stat = trade_stat[cols]\n",
    "    trade_stat['trade_log_return1'] = trade_stat.groupby(by = ['time_id'])['price'].apply(log_return).fillna(0)\n",
    "    trade_stat = trade_stat.groupby(by = ['stock_id', 'time_id'])[['trade_log_return1']]\\\n",
    "                           .agg(realized_volatility).reset_index()\n",
    "    #Joining book and trade features\n",
    "    stock_stat = stock_stat.merge(trade_stat, on=['stock_id', 'time_id'], how='left').fillna(-999)\n",
    "    \n",
    "    return stock_stat\n",
    "\n",
    "def get_dataSet(stock_ids : list, dataType = 'train'):\n",
    "\n",
    "    stock_stat = Parallel(n_jobs=-1)(\n",
    "        delayed(get_stock_stat)(stock_id, dataType) \n",
    "        for stock_id in stock_ids\n",
    "    )\n",
    "    \n",
    "    stock_stat_df = pd.concat(stock_stat, ignore_index = True)\n",
    "\n",
    "    return stock_stat_df\n",
    "\n",
    "def feval_RMSPE(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    return 'RMSPE', round(rmspe(y_true = labels, y_pred = preds),5), False\n",
    "\n",
    "params_lgbm = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': 0.01,\n",
    "        'objective': 'regression',\n",
    "        'metric': 'None',\n",
    "        'max_depth': -1,\n",
    "        'n_jobs': -1,\n",
    "        'feature_fraction': 0.7,\n",
    "        'bagging_fraction': 0.7,\n",
    "        'lambda_l2': 1,\n",
    "        'verbose': -1\n",
    "        #'bagging_freq': 5\n",
    "}\n",
    "\n",
    "train = pd.read_csv(os.path.join(path_data, 'train.csv'))\n",
    "train_stock_stat_df = get_dataSet(stock_ids = train['stock_id'].unique(), dataType = 'train')\n",
    "train = pd.merge(train, train_stock_stat_df, on = ['stock_id', 'time_id'], how = 'left')\n",
    "print('Train shape: {}'.format(train.shape))\n",
    "display(train.head(2))\n",
    "\n",
    "test = pd.read_csv(os.path.join(path_data, 'test.csv'))\n",
    "test_stock_stat_df = get_dataSet(stock_ids = test['stock_id'].unique(), dataType = 'test')\n",
    "test = pd.merge(test, test_stock_stat_df, on = ['stock_id', 'time_id'], how = 'left').fillna(0)\n",
    "print('Test shape: {}'.format(test.shape))\n",
    "display(test.head(2))\n",
    "\n",
    "cats = ['stock_id']\n",
    "model_name = 'lgb1'\n",
    "pred_name = 'pred_{}'.format(model_name)\n",
    "features_to_consider = ['stock_id', 'log_return1', 'log_return2', 'trade_log_return1']\n",
    "print('We consider {} features'.format(len(features_to_consider)))\n",
    "\n",
    "train[pred_name] = 0\n",
    "test['target'] = 0\n",
    "\n",
    "n_folds = 4\n",
    "n_rounds = 5000\n",
    "kf = model_selection.KFold(n_splits=n_folds, shuffle=True, random_state=2016)\n",
    "scores_folds[model_name] = []\n",
    "counter = 1\n",
    "for dev_index, val_index in kf.split(range(len(train))):\n",
    "    print('CV {}/{}'.format(counter, n_folds))\n",
    "    X_train = train.loc[dev_index, features_to_consider]\n",
    "    y_train = train.loc[dev_index, target_name].values\n",
    "    X_val = train.loc[val_index, features_to_consider]\n",
    "    y_val = train.loc[val_index, target_name].values\n",
    "    \n",
    "    #############################################################################################\n",
    "    #LGB\n",
    "    #############################################################################################\n",
    "    train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=cats, weight=1/np.power(y_train,2))\n",
    "    val_data = lgb.Dataset(X_val, label=y_val, categorical_feature=cats, weight=1/np.power(y_val,2))\n",
    "    \n",
    "    model = lgb.train(params_lgbm, \n",
    "                      train_data, \n",
    "                      n_rounds, \n",
    "                      valid_sets=val_data, \n",
    "                      feval=feval_RMSPE,\n",
    "                      verbose_eval= 250,\n",
    "                      early_stopping_rounds=500\n",
    "                     )\n",
    "    preds = model.predict(train.loc[val_index, features_to_consider])\n",
    "    train.loc[val_index, pred_name] = preds\n",
    "    score = round(rmspe(y_true = y_val, y_pred = preds),5)\n",
    "    print('Fold {} {}: {}'.format(counter, model_name, score))\n",
    "    scores_folds[model_name].append(score)\n",
    "    counter += 1\n",
    "    test[target_name] += model.predict(test[features_to_consider]).clip(0,1e10)\n",
    "del train_data, val_data\n",
    "test[target_name] = test[target_name]/n_folds\n",
    "\n",
    "score = round(rmspe(y_true = train[target_name].values, y_pred = train[pred_name].values),5)\n",
    "print('RMSPE {}: {} - Folds: {}'.format(model_name, score, scores_folds[model_name]))\n",
    "\n",
    "display(test[['row_id', target_name]].head(2))\n",
    "test[['row_id', target_name]].to_csv('submission.csv',index = False)\n",
    "\n",
    "importances = pd.DataFrame({'Feature': model.feature_name(), \n",
    "                            'Importance': model.feature_importance(importance_type='gain')})\n",
    "importances.sort_values(by = 'Importance', inplace=True)\n",
    "importances2 = importances.nlargest(50,'Importance', keep='first').sort_values(by='Importance', ascending=True)\n",
    "importances2[['Importance', 'Feature']].plot(kind = 'barh', x = 'Feature', figsize = (8,6), color = 'blue', fontsize=11);plt.ylabel('Feature', fontsize=12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
